{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Visualize_img+roi1+roi2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOf3fs9lsLeL+se/vYCuv4X"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Rv9bwzFFetzI","colab_type":"code","colab":{}},"source":["! pip install scikit-plot"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ob49lxTKsYGP","colab_type":"code","colab":{}},"source":["a = []\n","while(1):\n","    a.append('1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjlkyyzBe0Eb","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('always')\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9mTElTXne4_A","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCoKA1eHeYsc","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import dlib\n","import math\n","import numpy as np\n","\n","import scikitplot\n","import seaborn as sns\n","from matplotlib import pyplot\n","\n","import tensorflow as tf\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Concatenate\n","from tensorflow.keras.layers import Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import plot_model\n","\n","from keras import backend as K\n","from keras.utils import np_utils\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ab83Kwg9ejbj","colab_type":"code","colab":{}},"source":["np.random.seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7PWzrc9ijeb","colab_type":"code","colab":{}},"source":["DATA = \"CK\"\n","DATA_PATH = \"drive/My Drive/FER/datasets/CK+48/\"\n","BASE_PATH = \"drive/My Drive/FER/Colab/GauravSharma/Multi-Input-Model/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBm-OEcyfNTD","colab_type":"code","colab":{}},"source":["class_count = {}\n","for dir_ in os.listdir(DATA_PATH):\n","    count = 0\n","    for f in os.listdir(DATA_PATH + dir_ + \"/\"):\n","        count += 1\n","\n","    class_count[dir_] = count\n","    print(f\"{dir_} has {count} number of images\")\n","\n","total_images = sum(class_count.values())\n","print(f\"\\ntotal images are {total_images}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMl2v2oNfxc7","colab_type":"code","colab":{}},"source":["TOP_EMOTIONS = [\"happy\", \"fear\", \"sadness\", \"anger\", \"surprise\"]\n","\n","for k,v in class_count.items():\n","    if not k in TOP_EMOTIONS:\n","        total_images -= v\n","\n","total_images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xx6_JKYdgMg8","colab_type":"code","colab":{}},"source":["%%time\n","print(\"loading images to numpy array, this will take few minutes...\")\n","\n","img_arr = np.empty(shape=(total_images,48,48,1))\n","img_label = np.empty(shape=(total_images))\n","label_to_text = {}\n","\n","i = 0\n","label = 0\n","for dir_ in os.listdir(DATA_PATH):\n","    if dir_ in TOP_EMOTIONS:\n","        print(f\"loading {dir_} images to numpy arrays\")\n","        for f in os.listdir(DATA_PATH + dir_ + \"/\"):\n","            img_arr[i] = np.expand_dims(cv2.imread(DATA_PATH + dir_ + \"/\" + f, 0), axis=2)\n","            img_label[i] = label\n","            i += 1\n","        label_to_text[label] = dir_\n","        label += 1\n","\n","img_label = np_utils.to_categorical(img_label)\n","img_arr.shape, img_label.shape\n","\n","print(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JXYWn7Jgrzm","colab_type":"code","colab":{}},"source":["label_to_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7dquyRbg5Q0","colab_type":"code","colab":{}},"source":["text_to_label = dict((v,k) for k,v in label_to_text.items())\n","text_to_label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tc628IjJhaEy","colab_type":"code","colab":{}},"source":["img_arr = img_arr / 255."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOaTKWAfg6_p","colab_type":"code","colab":{}},"source":["num_emotions = len(TOP_EMOTIONS)\n","fig = pyplot.figure(1, (num_emotions*1.5, num_emotions*1.5))\n","\n","idx = 0\n","for k in label_to_text:\n","    sample_indices = np.random.choice(np.where(img_label[:,k]==1)[0], size=4, replace=False)\n","    sample_images = img_arr[sample_indices]\n","    for img in sample_images:\n","        idx += 1\n","        ax = pyplot.subplot(num_emotions,4,idx)\n","        ax.imshow(img.reshape(48,48), cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(label_to_text[k])\n","        pyplot.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LM-vNpqXh6ih","colab_type":"code","colab":{}},"source":["%%time\n","\n","print(\"Extracting facial ROI, this may take some time\")\n","\n","face_detector = dlib.get_frontal_face_detector()\n","shape_predictor = dlib.shape_predictor(BASE_PATH+\"dumps/shape_predictor_68_face_landmarks.dat\")\n","\n","ROI_1 = list(set(range(17,48)) - set(range(29,36)))\n","ROI_2 = list(range(48,68)) + [33, 4, 14]\n","roi1_arr = np.empty(shape=(total_images,25,50,1))\n","roi2_arr = np.empty(shape=(total_images,25,50,1))\n","\n","count = 0\n","idx = 0\n","for dir_ in os.listdir(DATA_PATH):\n","    if dir_ in TOP_EMOTIONS:\n","        print(f\"processing {dir_} images...\")\n","\n","        for f in os.listdir(DATA_PATH + dir_ + \"/\"):\n","            img = cv2.imread(DATA_PATH + dir_ + \"/\" + f, 0)\n","            img_ = cv2.resize(img, (96,96))\n","            # img_ = cv2.equalizeHist(img_)\n","\n","            faces = face_detector(img_)\n","            \n","            if faces:\n","                for face in faces:\n","                    ROI1_landmarks = []\n","                    ROI2_landmarks = []\n","                    landmarks = shape_predictor(img_, face)\n","                    for i in range(0, 68):\n","                        x = landmarks.part(i).x\n","                        y = landmarks.part(i).y\n","                        if i in ROI_1:\n","                            ROI1_landmarks.append((x,y))\n","                        if i in ROI_2:\n","                            ROI2_landmarks.append((x,y))\n","\n","                    (x, y, w, h) = cv2.boundingRect(np.array(ROI1_landmarks))\n","                    roi1 = img_[y:y + h, x:x + w]\n","                    roi1 = cv2.resize(roi1, (50,25), interpolation=cv2.INTER_CUBIC)\n","                    roi1_arr[idx] = np.expand_dims(roi1, axis=2)\n","\n","                    (x, y, w, h) = cv2.boundingRect(np.array(ROI2_landmarks))\n","                    roi2 = img_[y:y + h, x:x + w]\n","                    roi2 = cv2.resize(roi2, (50,25), interpolation=cv2.INTER_CUBIC)\n","                    roi2_arr[idx] = np.expand_dims(roi2, axis=2)\n","\n","                    idx += 1\n","            else:\n","                count += 1\n","\n","print(f\"\\ntotal images with no facial landmarks: {count}\")\n","\n","roi1_arr = np.array(roi1_arr)\n","print(\"ROI1\", roi1_arr.shape)\n","\n","roi2_arr = np.array(roi2_arr)\n","print(\"ROI2\", roi2_arr.shape)\n","\n","print(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EaheTUzlB7y","colab_type":"code","colab":{}},"source":["fig = pyplot.figure(1, (18,8))\n","\n","np.random.seed(10)\n","idx = 0\n","for k in label_to_text:\n","    sample_indices = np.random.choice(np.where(img_label[:,k]==1)[0], size=1, replace=False)\n","    sample_images = img_arr[sample_indices]\n","    sample_roi1 = roi1_arr[sample_indices]\n","    sample_roi2 = roi2_arr[sample_indices]\n","\n","    for img,roi1,roi2 in zip(sample_images, sample_roi1, sample_roi2):\n","        idx += 1\n","        ax = pyplot.subplot(5,3,idx)\n","        ax.imshow(img.reshape(48,48), cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(f\"Raw_Image, {label_to_text[k]}\")\n","\n","        idx += 1\n","        ax = pyplot.subplot(5,3,idx)\n","        ax.imshow(roi1.reshape(25,50), cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(\"ROI_1\")\n","\n","        idx += 1\n","        ax = pyplot.subplot(5,3,idx)\n","        ax.imshow(roi2.reshape(25,50), cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(\"ROI_2\")\n","\n","        pyplot.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rh6n58urwueI","colab_type":"code","colab":{}},"source":["hog_features = []\n","for dir_ in os.listdir(DATA_PATH):\n","    if dir_ in TOP_EMOTIONS:\n","        print(f\"processing {dir_} images...\")\n","\n","        for f in os.listdir(DATA_PATH + dir_ + \"/\"):\n","            img = cv2.imread(DATA_PATH + dir_ + \"/\" + f, 0)\n","            img_ = cv2.resize(img, (64,128))\n","            # img_ = cv2.equalizeHist(img_)\n","\n","            hog = cv2.HOGDescriptor()\n","            hog_descr = hog.compute(img_)\n","            hog_features.append(hog_descr)\n","\n","hog_features = np.array(hog_features)\n","print(hog_features.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OT7xVKM82G_j","colab_type":"code","colab":{}},"source":["Xtrain_img, Xtest_img, Xtrain_roi1, Xtest_roi1, Xtrain_roi2, Xtest_roi2, Xtrain_hogfeat, Xtest_hogfeat, y_train, y_test = \\\n","train_test_split(img_arr, roi1_arr, roi2_arr, hog_features, img_label,\n","                shuffle=True, stratify=img_label, train_size=0.7, random_state=42)\n","\n","print(Xtrain_img.shape, Xtrain_roi1.shape, Xtrain_roi2.shape, Xtrain_hogfeat.shape, y_train.shape)\n","print(Xtest_img.shape, Xtest_roi1.shape, Xtest_roi2.shape, Xtest_hogfeat.shape, y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJHte7Pq6kfy","colab_type":"code","colab":{}},"source":["def full_image_pipeline(input_shape):\n","    model_in = Input(shape=input_shape, name=\"input_DCNN\")\n","    \n","    conv2d_1 = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_1_img'\n","    )(model_in)\n","    batchnorm_1 = BatchNormalization(name='batchnorm_1_img')(conv2d_1)\n","    conv2d_2 = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_2_img'\n","    )(batchnorm_1)\n","    batchnorm_2 = BatchNormalization(name='batchnorm_2_img')(conv2d_2)\n","    \n","    maxpool2d_1 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_1_img')(batchnorm_2)\n","    dropout_1 = Dropout(0.4, name='dropout_1_img')(maxpool2d_1)\n","\n","    conv2d_3 = Conv2D(\n","        filters=128,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_3_img'\n","    )(dropout_1)\n","    batchnorm_3 = BatchNormalization(name='batchnorm_3_img')(conv2d_3)\n","    conv2d_4 = Conv2D(\n","        filters=128,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_4_img'\n","    )(batchnorm_3)\n","    batchnorm_4 = BatchNormalization(name='batchnorm_4_img')(conv2d_4)\n","    \n","    maxpool2d_2 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_2_img')(batchnorm_4)\n","    dropout_2 = Dropout(0.4, name='dropout_2_img')(maxpool2d_2)\n","\n","    conv2d_5 = Conv2D(\n","        filters=256,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_5_img'\n","    )(dropout_2)\n","    batchnorm_5 = BatchNormalization(name='batchnorm_5_img')(conv2d_5)\n","    conv2d_6 = Conv2D(\n","        filters=256,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_6_img'\n","    )(batchnorm_5)\n","    batchnorm_6 = BatchNormalization(name='batchnorm_6_img')(conv2d_6)\n","    \n","    maxpool2d_3 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_3_img')(batchnorm_6)\n","    dropout_3 = Dropout(0.4, name='dropout_3_img')(maxpool2d_3)\n","\n","    flatten = Flatten(name='flatten_dcnn_img')(dropout_3)\n","        \n","    dense_1 = Dense(\n","        128,\n","        activation='elu',\n","        kernel_initializer='he_normal',\n","        name='dense1_dcnn_img'\n","    )(flatten)\n","    batchnorm_7 = BatchNormalization(name='batchnorm_7_img')(dense_1)\n","    \n","    model_out = Dropout(0.6, name='dropout_4_img')(batchnorm_7)\n","    \n","    return model_in, model_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbM-oB_V6nkO","colab_type":"code","colab":{}},"source":["def roi1_pipeline(input_shape):\n","    model_in = Input(shape=input_shape, name=\"input_ROI1\")\n","    \n","    conv2d_1 = Conv2D(\n","        filters=32,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_1_roi1'\n","    )(model_in)\n","    batchnorm_1 = BatchNormalization(name='batchnorm_1_roi1')(conv2d_1)\n","    conv2d_2 = Conv2D(\n","        filters=32,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_2_roi1'\n","    )(batchnorm_1)\n","    batchnorm_2 = BatchNormalization(name='batchnorm_2_roi1')(conv2d_2)\n","    \n","    maxpool2d_1 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_1_roi1')(batchnorm_2)\n","    dropout_1 = Dropout(0.4, name='dropout_1_roi1')(maxpool2d_1)\n","\n","    conv2d_3 = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_3_roi1'\n","    )(dropout_1)\n","    batchnorm_3 = BatchNormalization(name='batchnorm_3_roi1')(conv2d_3)\n","    conv2d_4 = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_4_roi1'\n","    )(batchnorm_3)\n","    batchnorm_4 = BatchNormalization(name='batchnorm_4_roi1')(conv2d_4)\n","    \n","    maxpool2d_2 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_2_roi1')(batchnorm_4)\n","    dropout_2 = Dropout(0.4, name='dropout_2_roi1')(maxpool2d_2)\n","\n","    conv2d_5 = Conv2D(\n","        filters=128,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_5_roi1'\n","    )(dropout_2)\n","    batchnorm_5 = BatchNormalization(name='batchnorm_5_roi1')(conv2d_5)\n","    conv2d_6 = Conv2D(\n","        filters=128,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_6_roi1'\n","    )(batchnorm_5)\n","    batchnorm_6 = BatchNormalization(name='batchnorm_6_roi1')(conv2d_6)\n","    \n","    maxpool2d_3 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_3_roi1')(batchnorm_6)\n","    dropout_3 = Dropout(0.4, name='dropout_3_roi1')(maxpool2d_3)\n","\n","    flatten = Flatten(name='flatten_roi1')(dropout_3)\n","        \n","    dense_1 = Dense(\n","        128,\n","        activation='elu',\n","        kernel_initializer='he_normal',\n","        name='dense1_roi1'\n","    )(flatten)\n","    batchnorm_7 = BatchNormalization(name='batchnorm_7_roi1')(dense_1)\n","    \n","    model_out = Dropout(0.6, name='dropout_4_roi1')(batchnorm_7)\n","    \n","    return model_in, model_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcSGp_Di7TQP","colab_type":"code","colab":{}},"source":["def roi2_pipeline(input_shape):\n","    model_in = Input(shape=input_shape, name=\"input_ROI2\")\n","    \n","    conv2d_1 = Conv2D(\n","        filters=32,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_1_roi2'\n","    )(model_in)\n","    batchnorm_1 = BatchNormalization(name='batchnorm_1_roi2')(conv2d_1)\n","    conv2d_2 = Conv2D(\n","        filters=32,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_2_roi2'\n","    )(batchnorm_1)\n","    batchnorm_2 = BatchNormalization(name='batchnorm_2_roi2')(conv2d_2)\n","    \n","    maxpool2d_1 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_1_roi2')(batchnorm_2)\n","    dropout_1 = Dropout(0.4, name='dropout_1_roi2')(maxpool2d_1)\n","\n","    conv2d_3 = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_3_roi2'\n","    )(dropout_1)\n","    batchnorm_3 = BatchNormalization(name='batchnorm_3_roi2')(conv2d_3)\n","    conv2d_4 = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_4_roi2'\n","    )(batchnorm_3)\n","    batchnorm_4 = BatchNormalization(name='batchnorm_4_roi2')(conv2d_4)\n","    \n","    maxpool2d_2 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_2_roi2')(batchnorm_4)\n","    dropout_2 = Dropout(0.4, name='dropout_2_roi2')(maxpool2d_2)\n","\n","    conv2d_5 = Conv2D(\n","        filters=128,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_5_roi2'\n","    )(dropout_2)\n","    batchnorm_5 = BatchNormalization(name='batchnorm_5_roi2')(conv2d_5)\n","    conv2d_6 = Conv2D(\n","        filters=128,\n","        kernel_size=(3,3),\n","        activation='elu',\n","        padding='same',\n","        kernel_initializer='he_normal',\n","        name='conv2d_6_roi2'\n","    )(batchnorm_5)\n","    batchnorm_6 = BatchNormalization(name='batchnorm_6_roi2')(conv2d_6)\n","    \n","    maxpool2d_3 = MaxPooling2D(pool_size=(2,2), name='maxpool2d_3_roi2')(batchnorm_6)\n","    dropout_3 = Dropout(0.4, name='dropout_3_roi2')(maxpool2d_3)\n","\n","    flatten = Flatten(name='flatten_roi2')(dropout_3)\n","        \n","    dense_1 = Dense(\n","        128,\n","        activation='elu',\n","        kernel_initializer='he_normal',\n","        name='dense1_roi2'\n","    )(flatten)\n","    batchnorm_7 = BatchNormalization(name='batchnorm_7_roi2')(dense_1)\n","    \n","    model_out = Dropout(0.6, name='dropout_4_roi2')(batchnorm_7)\n","    \n","    return model_in, model_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V38SDxL9yoAM","colab_type":"code","colab":{}},"source":["def facial_HOGfeat_pipeline(input_shape):\n","    model_in = Input(shape=input_shape, name=\"input_HOGfeat\")\n","    flatten = Flatten(name=\"flatten_hogfeat\")(model_in)\n","    dense1 = Dense(256, activation=\"elu\", name=\"dense1_hogfeat\")(flatten)\n","    model_out = Dropout(0.4, name='dropout1_hogfeat')(dense1)\n","    return model_in, model_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRRXS6cv7mnU","colab_type":"code","colab":{}},"source":["def merge_models(models_in: list, models_out: list, num_classes: int, show_summary=False):\n","    \n","    concated = Concatenate()(models_out)\n","    dropout_1 = Dropout(0.3, name='dropout1_merged')(concated)\n","\n","    dense1 = Dense(128, activation=\"elu\", name=\"dense1_merged\")(dropout_1)\n","    dropout_2 = Dropout(0.5, name='dropout2_merged')(dense1)\n","\n","    out = Dense(num_classes, activation=\"softmax\", name=\"out_layer\")(dropout_2)\n","\n","    model = Model(inputs=models_in, outputs=out, name=\"Multi_Input_Model\")\n","\n","    if show_summary:\n","        model.summary()\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNVijEj-7tqZ","colab_type":"code","colab":{}},"source":["fullimg_in, fullimg_out = full_image_pipeline(input_shape=(48,48,1))\n","roi1_in, roi1_out = roi1_pipeline(input_shape=(25,50,1))\n","roi2_in, roi2_out = roi2_pipeline(input_shape=(25,50,1))\n","hogfeat_in, hogfeat_out = facial_HOGfeat_pipeline(input_shape=(3780,1))\n","\n","num_classes = y_train.shape[1]\n","\n","model = merge_models(\n","    models_in=[fullimg_in, roi1_in, roi2_in, ],\n","    models_out=[fullimg_out, roi1_out, roi2_out,],\n","    num_classes=num_classes,\n",")\n","\n","model_name = \"img+roi\"\n","plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True,\n","           dpi=50, to_file=BASE_PATH+f'/{model_name}_model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Lpmc82M8Khp","colab_type":"code","colab":{}},"source":["def data_generator(Xtrain_img, Xtrain_roi1, Xtrain_roi2, ytrain, batch_size):\n","    while True:\n","        idx = np.random.permutation(Xtrain_img.shape[0])\n","\n","        datagen = ImageDataGenerator(\n","            rotation_range=15,\n","            width_shift_range=0.15,\n","            height_shift_range=0.15,\n","            shear_range=0.15,\n","            zoom_range=0.15,\n","            horizontal_flip=True,\n","        )\n","\n","        batches_img = datagen.flow(Xtrain_img[idx], ytrain[idx], batch_size=batch_size, shuffle=False, seed=42)\n","        batches_img = datagen.flow(Xtrain_img[idx], ytrain[idx], batch_size=batch_size, shuffle=False, seed=42)\n","        batches_img = datagen.flow(Xtrain_img[idx], ytrain[idx], batch_size=batch_size, shuffle=False, seed=42)\n","        idx0 = 0\n","        for batch in batches:\n","            idx1 = idx0 + batch[0].shape[0]\n","\n","            yield [batch[0], Xtrain_hogimg[idx[ idx0:idx1 ]] ], batch[1]\n","\n","            idx0 = idx1\n","            if idx1 >= Xtrain_img.shape[0]:\n","                break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zOIVkDeG9aZS","colab_type":"code","colab":{}},"source":["early_stopping = EarlyStopping(\n","    monitor='val_accuracy',\n","    min_delta=0.00008,\n","    patience=12,\n","    verbose=1,\n","    restore_best_weights=True,\n",")\n","\n","lr_scheduler = ReduceLROnPlateau(\n","    monitor='val_accuracy',\n","    min_delta=0.00008,\n","    factor=0.3,\n","    patience=5,\n","    min_lr=1e-6,\n","    verbose=1,\n",")\n","\n","callbacks = [\n","    early_stopping,\n","    lr_scheduler,\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VA7klEwE9c80","colab_type":"code","colab":{}},"source":["batch_size = 10\n","epochs = 60\n","lr = 0.001\n","optim = optimizers.Adam(learning_rate=lr)\n","\n","model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer=optim,\n","        metrics=['accuracy']\n",")\n","\n","history = model.fit(\n","    x=[Xtrain_img, Xtrain_roi1, Xtrain_roi2],\n","    y=y_train,\n","    validation_data=([Xtest_img, Xtest_roi1, Xtest_roi2], y_test),\n","    epochs=epochs,\n","    callbacks=callbacks,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_3yeRvX-D4g","colab_type":"code","colab":{}},"source":["sns.set()\n","fig = pyplot.figure(0, (12, 4))\n","\n","ax = pyplot.subplot(1, 2, 1)\n","sns.lineplot(history.epoch, history.history['accuracy'], label='train')\n","sns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\n","pyplot.title('Accuracy')\n","pyplot.tight_layout()\n","\n","ax = pyplot.subplot(1, 2, 2)\n","sns.lineplot(history.epoch, history.history['loss'], label='train')\n","sns.lineplot(history.epoch, history.history['val_loss'], label='valid')\n","pyplot.title('Loss')\n","pyplot.tight_layout()\n","\n","pyplot.savefig(BASE_PATH + f'epoch_metrics/{model_name}_{num_classes}emo.png')\n","pyplot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3PrH39sd-Ry0","colab_type":"code","colab":{}},"source":["yhat_test = model.predict([Xtest_img, Xtest_roi1, Xtest_roi2])\n","yhat_test = np.argmax(yhat_test, axis=1)\n","ytest_ = np.argmax(y_test, axis=1)\n","\n","scikitplot.metrics.plot_confusion_matrix(ytest_, yhat_test, figsize=(7,7))\n","pyplot.savefig(BASE_PATH + f'confusion_matrix/{model_name}_{num_classes}emo.png')\n","\n","test_accu = np.sum(ytest_ == yhat_test) / len(ytest_) * 100\n","print(f\"test accuracy: {round(test_accu, 4)} %\\n\\n\")\n","\n","print(classification_report(ytest_, yhat_test))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwuNTbbRff8D","colab_type":"text"},"source":["### Visualizing the Model"]},{"cell_type":"code","metadata":{"id":"j75mzkg5ffhA","colab_type":"code","colab":{}},"source":["sns.reset_orig()\n","\n","images = [Xtest_img[0], Xtest_roi1[0], Xtest_roi2[0]]\n","\n","pyplot.figure(1, (16,4))\n","for idx,img in enumerate(images):\n","    ax = pyplot.subplot(1,3,idx+1)\n","    if idx:\n","        ax.imshow(img.reshape(25,50), cmap=\"gray\")\n","    else:\n","        ax.imshow(img.reshape(48,48), cmap=\"gray\")\n","    pyplot.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUvAYf9r_Cmm","colab_type":"code","colab":{}},"source":["images_ = [np.expand_dims(img, axis=0) for img in images]\n","images_[0].shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmTr4dc3hqln","colab_type":"code","colab":{}},"source":["layer_list = [(layer.name, layer) for layer in model.layers if \"conv\" in layer.name]\n","layer_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBsd4ShJhfRD","colab_type":"code","colab":{}},"source":["%%time\n","\n","INTERESTED_CONV_LAYERS = [\"conv2d_1_img\", \"conv2d_1_roi1\", \"conv2d_1_roi2\"]\n","i = 1\n","for layer in layer_list:\n","    if layer[0] in INTERESTED_CONV_LAYERS:    \n","        model_conv2d = Model(inputs=model.inputs, outputs=layer[1].output)\n","        featuremaps_conv2d = model_conv2d.predict(images_)\n","\n","        if \"roi\" in layer[0]:\n","            cols = 12\n","            rows = math.ceil(featuremaps_conv2d.shape[-1] / cols)\n","        else:\n","            cols = 20\n","            rows = math.ceil(featuremaps_conv2d.shape[-1] / cols)\n","\n","        fig = pyplot.figure(i, (20, rows))\n","        i += 1\n","        \n","        for idx, feature_map in enumerate(np.rollaxis(featuremaps_conv2d, axis=3)):\n","            ax = pyplot.subplot(rows, cols ,idx+1)\n","            ax.imshow(feature_map[0], cmap=\"gray\")\n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","            pyplot.suptitle(f\"layer name: {layer[0]}, feature map shape: {featuremaps_conv2d.shape}\", fontsize=20, y=1.1)\n","            pyplot.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S7_sm0myiDNE","colab_type":"code","colab":{}},"source":["%%time\n","\n","INTERESTED_CONV_LAYERS = [\"conv2d_3_img\", \"conv2d_3_roi1\", \"conv2d_3_roi2\"]\n","i = 1\n","for layer in layer_list:\n","    if layer[0] in INTERESTED_CONV_LAYERS:    \n","        model_conv2d = Model(inputs=model.inputs, outputs=layer[1].output)\n","        featuremaps_conv2d = model_conv2d.predict(images_)\n","\n","        if \"roi\" in layer[0]:\n","            cols = 12\n","            rows = math.ceil(featuremaps_conv2d.shape[-1] / cols)\n","        else:\n","            cols = 20\n","            rows = math.ceil(featuremaps_conv2d.shape[-1] / cols)\n","\n","        fig = pyplot.figure(i, (20, rows))\n","        i += 1\n","        \n","        for idx, feature_map in enumerate(np.rollaxis(featuremaps_conv2d, axis=3)):\n","            ax = pyplot.subplot(rows, cols ,idx+1)\n","            ax.imshow(feature_map[0], cmap=\"gray\")\n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","            pyplot.suptitle(f\"layer name: {layer[0]}, feature map shape: {featuremaps_conv2d.shape}\", fontsize=20, y=1.1)\n","            pyplot.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5p_OhbvTjlrS","colab_type":"code","colab":{}},"source":["%%time\n","\n","INTERESTED_CONV_LAYERS = [\"conv2d_6_img\", \"conv2d_6_roi1\", \"conv2d_6_roi2\"]\n","i = 1\n","for layer in layer_list:\n","    if layer[0] in INTERESTED_CONV_LAYERS:    \n","        model_conv2d = Model(inputs=model.inputs, outputs=layer[1].output)\n","        featuremaps_conv2d = model_conv2d.predict(images_)\n","\n","        if \"roi\" in layer[0]:\n","            cols = 12\n","            rows = math.ceil(featuremaps_conv2d.shape[-1] / cols)\n","            featuremaps_conv2d = featuremaps_conv2d[:,:,:,:100]\n","        else:\n","            cols = 20\n","            rows = math.ceil(featuremaps_conv2d.shape[-1] / cols)\n","            featuremaps_conv2d = featuremaps_conv2d[:,:,:,:60]\n","\n","        fig = pyplot.figure(i, (20, rows))\n","        i += 1\n","        \n","        for idx, feature_map in enumerate(np.rollaxis(featuremaps_conv2d, axis=3)):\n","            ax = pyplot.subplot(rows, cols ,idx+1)\n","            ax.imshow(feature_map[0], cmap=\"gray\")\n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","            pyplot.suptitle(f\"layer name: {layer[0]}, feature map shape: {featuremaps_conv2d.shape}\", fontsize=20, y=1.1)\n","            pyplot.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X8ld_tv4moXO","colab_type":"text"},"source":["#### Let's plot Class Activation Map (CAM)"]},{"cell_type":"code","metadata":{"id":"a4kobIDRkWSy","colab_type":"code","colab":{}},"source":["%%time\n","\n","INTERESTED_CONV_LAYERS = [\"conv2d_1_img\", \"conv2d_1_roi1\", \"conv2d_1_roi2\"]\n","\n","preds = model.predict(images_)\n","label_to_text[np.argmax(preds[0])]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2tIX31RUm1VB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}